{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score,roc_auc_score \n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The path for importing the dataset needs to be changed to where your winequality-white.csv file is located",
    
    "df = pd.read_csv('/Users/camillaandersson/Documents/Høst 2020 - NTNU/Maskinlæring/Project/winequality-white.csv', delimiter=\";\")\n",
    "#Data visualization\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide quality into bad, good, and average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/muammerhuseyinoglu/prediction-of-wine-quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify the quality\n",
    "quality = df[\"quality\"].values\n",
    "category = []\n",
    "for num in quality:\n",
    "    if num<5:\n",
    "        category.append(0) #Bad\n",
    "    elif num>6:\n",
    "        category.append(2) #Good\n",
    "    else:\n",
    "        category.append(1) #Average\n",
    "\n",
    "#Create new data\n",
    "category = pd.DataFrame(data=category, columns=[\"category\"])\n",
    "data = pd.concat([df,category],axis=1)\n",
    "data.drop(columns=\"quality\",axis=1,inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows and columns\n",
    "print(\"Rows, columns: \" + str(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = data['category'].value_counts()\n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(data[\"category\"],palette=\"muted\")\n",
    "plt.title('Distribution of bad, average and good quality wine', fontsize = 20)\n",
    "plt.xticks(np.arange(3), ['Bad', 'Average', 'Good'])\n",
    "data[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap\n",
    "sns.heatmap(data.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/datadriveninvestor/regression-from-scratch-wine-quality-prediction-d61195cb91c8\n",
    "correlations = data.corr()['category'].sort_values(ascending=False)\n",
    "print(\"\\033[1m\"+ \"Correlations:\"+\"\\033[0m\")\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize, encode and split into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('category', axis=1)\n",
    "y = data['category']\n",
    "\n",
    "# Encode target\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)\n",
    "\n",
    "# Standarize X so that X_train and X_test is standarized\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#Train and Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train: \" + str(X_train.shape))\n",
    "print(\"y_train: \" + str(y_train.shape))\n",
    "print(\"X_test: \" + str(X_test.shape))\n",
    "print(\"y_test: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method for confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/58799204/confusion-martix-showing-the-values-with-cutting-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.array(['0','1', '2'])\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    plt.xlim(-0.5, len(np.unique(y))-0.5) # ADD THIS LINE\n",
    "    plt.ylim(len(np.unique(y))-0.5, -0.5) # ADD THIS LINE\n",
    "    return ax\n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/datadriveninvestor/k-nearest-neighbors-in-python-hyperparameters-tuning-716734bc557f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch Standard KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List Hyperparameters that we want to tune.\n",
    "n_neighbors = list(range(1,60))\n",
    "p=[1,2]\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(n_neighbors=n_neighbors, p=p)\n",
    "#Create new KNN object\n",
    "knn_base = KNeighborsClassifier()\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(knn_base, hyperparameters, cv=10)\n",
    "#Fit the model\n",
    "best_model = clf.fit(X,y)\n",
    "#Print The value of best Hyperparameters\n",
    "print('Standard KNN')\n",
    "print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch Weighted KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List Hyperparameters that we want to tune.\n",
    "n_neighbors = list(range(1,60))\n",
    "p=[1,2]\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(n_neighbors=n_neighbors, p=p)\n",
    "#Create new KNN object\n",
    "knn_base_2 = KNeighborsClassifier(weights = 'distance')\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(knn_base_2, hyperparameters, cv=10)\n",
    "#Fit the model\n",
    "best_model = clf.fit(X,y)\n",
    "#Print The value of best Hyperparameters\n",
    "print('Weighted KNN')\n",
    "print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/muammerhuseyinoglu/prediction-of-wine-quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "knn_standard = KNeighborsClassifier(n_neighbors=32, p=1) \n",
    "#fit model\n",
    "knn_standard.fit(X_train,y_train)\n",
    "#predict model\n",
    "pred_knn_standard=knn_standard.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate probability estimates for parameter y_score in roc_auc_score:\n",
    "pred_knn_standard_prob = knn_standard.predict_proba(X_test)\n",
    "\n",
    "#https://www.kaggle.com/muammerhuseyinoglu/prediction-of-wine-quality\n",
    "conclusion = pd.DataFrame({'model': [\"Standard KNN\"],\n",
    "                           'accuracy': [accuracy_score(y_test,pred_knn_standard)], \n",
    "                           'F1-score': [f1_score(y_test,pred_knn_standard,average='macro')],\n",
    "                          'ROC AUC': [roc_auc_score(y_test, pred_knn_standard_prob, multi_class = 'ovo')]})\n",
    "conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, pred_knn_standard, classes=class_names,\n",
    "                      title='Confusion matrix - Standard KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "knn_weighted = KNeighborsClassifier(weights = 'distance',n_neighbors=48, p=1)\n",
    "#fit model\n",
    "knn_weighted.fit(X_train,y_train)\n",
    "#predict model\n",
    "pred_knn_weighted=knn_weighted.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate probability estimates for parameter y_score in roc_auc_score:\n",
    "pred_knn_weighted_prob = knn_weighted.predict_proba(X_test)\n",
    "\n",
    "#https://www.kaggle.com/muammerhuseyinoglu/prediction-of-wine-quality\n",
    "conclusion = pd.DataFrame({'model': [\"Weighted KNN\"],\n",
    "                           'accuracy': [accuracy_score(y_test,pred_knn_weighted)], \n",
    "                           'F1-score': [f1_score(y_test,pred_knn_weighted,average='macro')],\n",
    "                          'ROC AUC': [roc_auc_score(y_test, pred_knn_weighted_prob, multi_class = 'ovo')]})\n",
    "conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, pred_knn_weighted, classes=class_names,\n",
    "                      title='Confusion matrix - Weighted KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN with SVM-SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversampling the data with RandomOverSampler\n",
    "smote = SVMSMOTE()\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "knn_smote = KNeighborsClassifier(n_neighbors=48, p=1)\n",
    "#fit model\n",
    "knn_smote.fit(X_train_smote,y_train_smote)\n",
    "#predict model\n",
    "pred_knn_smote=knn_smote.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate probability estimates for parameter y_score in roc_auc_score:\n",
    "pred_knn_smote_prob = knn_smote.predict_proba(X_test)\n",
    "\n",
    "#https://www.kaggle.com/muammerhuseyinoglu/prediction-of-wine-quality\n",
    "conclusion = pd.DataFrame({'model': [\"KNN with SVM-SMOTE\"],\n",
    "                           'accuracy': [accuracy_score(y_test,pred_knn_smote)], \n",
    "                           'F1-score': [f1_score(y_test,pred_knn_smote,average='macro')],\n",
    "                          'ROC AUC': [roc_auc_score(y_test, pred_knn_smote_prob, multi_class = 'ovo')]})\n",
    "conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, pred_knn_smote, classes=class_names,\n",
    "                      title='Confusion matrix - KNN with SMOTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame({'model': [\"Standard KNN\", \"Weighted KNN\", \"KNN with SMOTE\"], \n",
    "                           'accuracy': [100*accuracy_score(y_test,pred_knn_standard), 100*accuracy_score(y_test,pred_knn_weighted), 100*accuracy_score(y_test,pred_knn_smote)], \n",
    "                           'F1-score': [100*f1_score(y_test,pred_knn_standard,average='macro'), 100*f1_score(y_test,pred_knn_weighted,average='macro'), 100*f1_score(y_test,pred_knn_smote,average='macro')],\n",
    "                          'ROC AUC': [100*roc_auc_score(y_test, pred_knn_standard_prob, multi_class = 'ovo'), 100*roc_auc_score(y_test, pred_knn_weighted_prob, multi_class = 'ovo'), 100*roc_auc_score(y_test, pred_knn_smote_prob, multi_class = 'ovo')]})\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid search to find the best parameters\n",
    "parameters = {'kernel':('rbf', 'linear'), 'C':[0.1, 1.0, 10.0, 100.0], 'gamma':[0.5, 1, 10]}\n",
    "\n",
    "SVC= svm.SVC()\n",
    "gscv = GridSearchCV(SVC, param_grid=parameters, cv=2)\n",
    "gscv.fit(X_train, y_train)\n",
    "\n",
    "print(gscv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with no weighting and oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM model 1: No weighting, no oversampling\n",
    "SVC = svm.SVC(kernel='rbf', gamma= 1, C=10, probability=True)\n",
    "SVC.fit(X_train, y_train)\n",
    "y_pred = SVC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Results for SVM model 1\n",
    "y_pred_prob = SVC.predict_proba(X_test)\n",
    "\n",
    "conclusion = pd.DataFrame({'model': [\"Standard SVM\"],\n",
    "                           'accuracy': [accuracy_score(y_test,y_pred)], \n",
    "                           'F1-score': [f1_score(y_test,y_pred,average='macro')],\n",
    "                          'ROC AUC': [roc_auc_score(y_test, y_pred_prob, multi_class = 'ovo', average ='macro')]})\n",
    "conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
    "                      title='Confusion matrix - Standard SVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with balanced weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid search to find the best parameters\n",
    "parameters = {'kernel':('rbf', 'linear'), 'C':[0.1, 1.0, 10.0, 100.0], 'gamma':[0.5, 1, 10]}\n",
    "\n",
    "SVC= svm.SVC(class_weight = 'balanced')\n",
    "gscv = GridSearchCV(SVC, param_grid=parameters, cv=2)\n",
    "gscv.fit(X_train, y_train)\n",
    "\n",
    "print(gscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM model 2: With balanced weights\n",
    "SVC_w = svm.SVC(kernel='rbf', C=100, gamma=1, class_weight = 'balanced', probability=True)\n",
    "SVC_w.fit(X_train, y_train)\n",
    "y_pred_w = SVC_w.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Results for SVM model 1\n",
    "y_pred_prob_w = SVC_w.predict_proba(X_test)\n",
    "conclusion = pd.DataFrame({'model': [\"weighted SVM\"],\n",
    "                           'accuracy': [accuracy_score(y_test,y_pred_w)], \n",
    "                           'F1-score': [f1_score(y_test,y_pred_w,average='macro')],\n",
    "                          'ROC AUC': [roc_auc_score(y_test, y_pred_prob_w, multi_class = 'ovo', average = 'macro')]})\n",
    "conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred_w, classes=class_names,\n",
    "                      title='Confusion matrix - Weighted SVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversampling the data with SMOTE\n",
    "smote = SVMSMOTE()\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New grid search with oversampled data\n",
    "parameters = {'kernel':('rbf', 'linear'), 'C':[0.1, 1.0, 10.0, 100.0], 'gamma':[0.5, 1, 10]}\n",
    "\n",
    "SVC= svm.SVC()\n",
    "gscv = GridSearchCV(SVC, param_grid=parameters, cv=4)\n",
    "gscv.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "print(gscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM model 3: SVM trained with oversampled data\n",
    "SVC_smote = svm.SVC(kernel='rbf', C=100, gamma=1, probability=True)\n",
    "SVC_smote.fit(X_train_smote, y_train_smote)\n",
    "y_pred_smote = SVC_smote.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Results for SVM model 3:\n",
    "y_pred_prob_smote = SVC_smote.predict_proba(X_test)\n",
    "conclusion = pd.DataFrame({'model': [\"SVM with SMOTE\"],\n",
    "                           'accuracy': [accuracy_score(y_test,y_pred_smote)], \n",
    "                           'F1-score': [f1_score(y_test,y_pred_smote,average='macro')],\n",
    "                          'ROC AUC': [roc_auc_score(y_test, y_pred_prob_smote, multi_class = 'ovo', average = 'macro')]})\n",
    "conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred_smote, classes=class_names,\n",
    "                      title='Confusion matrix - SVM with SMOTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total results\n",
    "summary = pd.DataFrame({'model': [\"Standard SVM\", \"Weighted SVM\", \"SVM with SMOTE\"], \n",
    "                           'accuracy': [100*accuracy_score(y_test,y_pred), 100*accuracy_score(y_test,y_pred_w), 100*accuracy_score(y_test,y_pred_smote)], \n",
    "                           'F1-score': [100*f1_score(y_test,y_pred,average='macro'), 100*f1_score(y_test,y_pred_w,average='macro'), 100*f1_score(y_test,y_pred_smote,average='macro')],\n",
    "                          'ROC AUC': [100*roc_auc_score(y_test, y_pred_prob, multi_class = 'ovo', average = 'macro'), 100*roc_auc_score(y_test, y_pred_prob_w, multi_class = 'ovo', average = 'macro'), 100*roc_auc_score(y_test, y_pred_prob_smote, multi_class = 'ovo', average = 'macro')]})\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Investigate default parameters\n",
    "rfc = RandomForestClassifier() \n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rfc.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find best hyperparameters using randomized search with cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First define parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 1000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rfc_base = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rfc_base, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=1, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "rfc_standard = RandomForestClassifier(n_estimators=670, min_samples_split = 2, min_samples_leaf=1, \n",
    "                                      max_features = 'auto', max_depth = 100, bootstrap = True)\n",
    "#fit model\n",
    "rfc_standard.fit(X_train, y_train)\n",
    "#predict model\n",
    "pred_rfc_standard = rfc_standard.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate probability estimates for parameter y_score in roc_auc_score:\n",
    "pred_rfc_standard_prob = rfc_standard.predict_proba(X_test)\n",
    "\n",
    "#https://www.kaggle.com/muammerhuseyinoglu/prediction-of-wine-quality\n",
    "conclusion = pd.DataFrame({'model': [\"Random Forest\"],\n",
    "                           'accuracy': [accuracy_score(y_test,pred_rfc_standard)], \n",
    "                           'F1-score': [f1_score(y_test,pred_rfc_standard,average='macro')],\n",
    "                          'ROC AUC': [roc_auc_score(y_test, pred_rfc_standard_prob, multi_class = 'ovo')]})\n",
    "conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, pred_rfc_standard, classes=class_names,\n",
    "                      title='Confusion matrix - Standard RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find best set of hyperparameters for weighted RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rfc_base_weighted = RandomForestClassifier(class_weight='balanced')\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rfc_base_weighted, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=1, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_weighted = RandomForestClassifier(n_estimators=670, min_samples_split = 2, min_samples_leaf=1, \n",
    "                                      max_features = 'auto', max_depth = 100, bootstrap = True,\n",
    "                                      class_weight='balanced')\n",
    "rfc_weighted = rfc_weighted.fit(X_train, y_train)\n",
    "pred_rfc_weighted = rfc_weighted.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate probability estimates for parameter y_score in roc_auc_score:\n",
    "pred_rfc_weighted_prob = rfc_weighted.predict_proba(X_test)\n",
    "\n",
    "conclusion = pd.DataFrame({'model': [\"Random Forest\"],\n",
    "                           'accuracy': [accuracy_score(y_test,pred_rfc_weighted)], \n",
    "                           'F1-score': [f1_score(y_test,pred_rfc_weighted,average='macro')],\n",
    "                          'ROC AUC': [roc_auc_score(y_test, pred_rfc_weighted_prob, multi_class = 'ovo')]})\n",
    "conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix \n",
    "plot_confusion_matrix(y_test, pred_rfc_weighted, classes=class_names,\n",
    "                      title='Confusion matrix - Weighted RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest With Bootstrap Class Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_BCW = RandomForestClassifier(n_estimators=670, min_samples_split = 2, min_samples_leaf=1, \n",
    "                                      max_features = 'auto', max_depth = 100, bootstrap = True,\n",
    "                                      class_weight='balanced_subsample')\n",
    "rfc_BCW.fit(X_train, y_train)\n",
    "pred_rfc_BCW = rfc_BCW.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate probability estimates for parameter y_score in roc_auc_score:\n",
    "pred_rfc_BCW_prob = rfc_BCW.predict_proba(X_test)\n",
    "\n",
    "conclusion = pd.DataFrame({'model': [\"Random Forest\"],\n",
    "                           'accuracy': [accuracy_score(y_test,pred_rfc_BCW)], \n",
    "                           'F1-score': [f1_score(y_test,pred_rfc_BCW,average='macro')],\n",
    "                          'ROC AUC': [roc_auc_score(y_test, pred_rfc_BCW_prob, multi_class = 'ovo')]})\n",
    "conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix \n",
    "plot_confusion_matrix(y_test, pred_rfc_BCW, classes=class_names,\n",
    "                      title='Confusion matrix - Bootstrap Class Weighted RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest using oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVMSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversampling the data with RandomOverSampler\n",
    "svmsmote = SVMSMOTE()\n",
    "X_train_svmsmote, y_train_svmsmote = svmsmote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "rfc_svmsmote = RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rfc_random = RandomizedSearchCV(estimator = rfc_svmsmote, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=1, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rfc_random.fit(X_train_svmsmote, y_train_svmsmote)\n",
    "rfc_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define model with correct parameters\n",
    "rfc_svmsmote = RandomForestClassifier(n_estimators=450, min_samples_split = 2, min_samples_leaf=1, \n",
    "                                      max_features = 'auto', max_depth = 50, bootstrap = True)\n",
    "\n",
    "# Random forest trained with oversampled data\n",
    "rfc_svmsmote.fit(X_train_svmsmote, y_train_svmsmote)\n",
    "pred_rfc_svmsmote = rfc_smote.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rfc_svmsmote_prob = rfc_svmsmote.predict_proba(X_test)\n",
    "\n",
    "conclusion = pd.DataFrame({'model': [\"Random Forest\"],\n",
    "                           'accuracy': [accuracy_score(y_test,pred_rfc_smote)], \n",
    "                           'F1-score': [f1_score(y_test,pred_rfc_smote,average='macro')],\n",
    "                          'ROC AUC': [roc_auc_score(y_test, pred_rfc_svmsmote_prob, multi_class = 'ovo')]})\n",
    "conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix \n",
    "plot_confusion_matrix(y_test, pred_rfc_smote, classes=class_names,\n",
    "                      title='Confusion matrix - RF with SVMSMOTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversampling the data with RandomOverSampler\n",
    "smote = SMOTE()\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "rfc_smote = RandomForestClassifier()\n",
    "\n",
    "#Oversampling the data with RandomOverSampler\n",
    "smote = SMOTE()\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rfc_random = RandomizedSearchCV(estimator = rfc_smote, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=1, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rfc_random.fit(X_train_smote, y_train_smote)\n",
    "rfc_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define model with correct parameters\n",
    "rfc_smote = RandomForestClassifier(n_estimators=450, min_samples_split = 2, min_samples_leaf=1, \n",
    "                                      max_features = 'auto', max_depth = 50, bootstrap = True)\n",
    "\n",
    "# Random forest trained with oversampled data\n",
    "rfc_smote.fit(X_train_smote, y_train_smote)\n",
    "pred_rfc_smote = rfc_smote.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate probability estimates for parameter y_score in roc_auc_score:\n",
    "pred_rfc_smote_prob = rfc_smote.predict_proba(X_test)\n",
    "\n",
    "conclusion = pd.DataFrame({'model': [\"Random Forest\"],\n",
    "                           'accuracy': [accuracy_score(y_test,pred_rfc_smote)], \n",
    "                           'F1-score': [f1_score(y_test,pred_rfc_smote,average='macro')],\n",
    "                          'ROC AUC': [roc_auc_score(y_test, pred_rfc_smote_prob, multi_class = 'ovo')]})\n",
    "conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix \n",
    "plot_confusion_matrix(y_test, pred_rfc_smote, classes=class_names,\n",
    "                      title='Confusion matrix - RF with SMOTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame({'model': [\"Standard Random Forest\", \"Weighted Random Forest\", \"Random Forest With Bootstrap Class Weighting\", \"Random Forest with SMOTE\"], \n",
    "                           'accuracy': [100*accuracy_score(y_test,pred_rfc_standard), 100*accuracy_score(y_test,pred_rfc_weighted), 100*accuracy_score(y_test,pred_rfc_BCW), 100*accuracy_score(y_test,pred_rfc_smote)], \n",
    "                           'F1-score': [100*f1_score(y_test,pred_rfc_standard,average='macro'), 100*f1_score(y_test,pred_rfc_weighted,average='macro'), 100*f1_score(y_test,pred_rfc_BCW,average='macro'), 100*f1_score(y_test,pred_rfc_smote,average='macro')],\n",
    "                          'ROC AUC': [100*roc_auc_score(y_test, pred_rfc_standard_prob, average='macro', multi_class = 'ovo'), 100*roc_auc_score(y_test, pred_rfc_weighted_prob, average='macro', multi_class = 'ovo'), 100*roc_auc_score(y_test, pred_rfc_BCW_prob, average='macro', multi_class = 'ovo'), 100*roc_auc_score(y_test, pred_rfc_smote_prob, average='macro', multi_class = 'ovo')]})\n",
    "\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
